###Commandline-level process
#Software and tools
Command-line level processes done in WSL2 workspace:
  wsl

Original setup of environment following Griffithlab tutorial (https://rnabio.org/module-00-setup/0000/09/01/Environment/) and Danny Arends tutorial (https://www.youtube.com/watch?v=PlqDQBl22DI), modified for Kallisto pseudoaligner readcounting. Links in bin for software currently installed. For each software, after creating link (ln -s /SOFTWAREPATH SYMBOLIC_LINK), usually required to give permissions through "chmod a+x SOFTWARE" command in bin directory. Below is list of cmdline tools/software used in this process, and their symbolic link names for my own use.

  ln -s /home/aurelien/software/kallisto/kallisto kallisto --> using as pseudoalignment tool to build alignment file and do read counts
  ln -s /home/aurelien/software/FastQC/fastqc fastqc --> using to check raw/cleaned data quality
  ln -s /home/aurelien/software/cufflinks-2.2.1.Linux_x86_64/cuffmerge cuffmerge --> useful tool to merge genome assemblies together, e.g. when building the drosophila melanogaster genome fasta 
  ln -s /home/aurelien/software/htslib/bgzip bgzip --> to compress or extract zip formats, here gz files (gzip), when troubleshooting data files and their quality    
  ln -s /home/aurelien/software/fastp/fastp fastp --> using to trim/clean reads
  ln -s /home/aurelien/software/cufflinks-2.2.1.Linux_x86_64/gffread gffread --> using to make fai file 
 
#Setup
Below line to mount/remount the drive with your data into your WSL accession, change driver letter accordingly:
  sudo mount -t drvfs d: /mnt/d

Go to folder location containing all data files, then get the names for each file in two arrays separated for pair 1 or pair 2 of each sample readpair respectively (change code if read files are named differently):
  read1s=(*1.fq.gz)
  read2s=(*2.fq.gz)
Sorting each array alphabetically to ensure they will be in the same order for later functions:
  read1s=($(sort <<<"${read1s[*]}"))
  read2s=($(sort <<<"${read2s[*]}"))
check the read arrays match in order:
  for ((i=0;i<25;++i));do echo ${read1s[i]};echo ${read2s[i]};  done
Saving both read arrays in bash script format using declare:
  declare -p read1s read2s > /home/data/samples_pqsR.txt
Then, just load the read1s and read2s arrays into the commandline variables when starting up:
  . samples_pqsR.txt

#Building index and mapping
Will only need to redo this if a new genome build is released before the data is acquired. Genome, gtf, index, kallisto index files available in sharepoint. Current build - Ensembl release 114, BDGP 6.56.
Built the full genome assembly from ensembl release fasta/fastq files for each chromosome assembly, mitochondrial dna assembly, and non-chromosomal genes, downloaded from their ftp server(see //wsl.localhost/Ubuntu/home/aurelien/genome/genomer.R)

gffread takes gtf file and genome fasta, first builds a fai index file to locate/index genetic features from the genome fasta, then -w option makes it write a FASTA file with spliced exons for each transcript. Basically this command generates a FASTA file with the DNA sequences for all transcripts in a GFF file. (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7222033/). Change transcripts_annotated output location when using:

  gffread Drosophila_melanogaster.BDGP6.46.112.gtf -g Drosophila_melanogaster.BDGP6.46.dna_sm.genome.fa -w ~/data/newresults/Drosophila_melanogaster.BDGP6.46.dna_sm.transcripts_annotated.fa

newvers
  gffread Drosophila_melanogaster.BDGP6.54.114.gtf -g Drosophila_melanogaster.BDGP6.54.dna.primary_assembly.fa -w ~/data/newresults/Drosophila_melanogaster.BDGP6.54.dna.transcripts_annotated.fa


# create an index of the transcriptome file made above
  kallisto index -i Drosophila_melanogaster.BDGP6.46.dna_sm.transcripts.fai Drosophila_melanogaster.BDGP6.46.dna_sm.transcripts_annotated.fa --verbose

newvers
  kallisto index -i Drosophila_melanogaster.BDGP6.54.dna.transcripts.fai Drosophila_melanogaster.BDGP6.54.dna.transcripts_annotated.fa --verbose
#Checking data quality
Go to folder location containing all data folders, then run fastQC to create qc reports of every data file:
  fastqc *.fq.gz --memory 4096 -t 4 -o /mnt/c/Users/Aurelien/Expansion/proj28/qual_reports/fastqc
When all fastqc's are done, run this to create one html file with the fastQC report data for all read files:
  multiqc ./ -o multiqc -s -v  

#Trimming data
Removal of duplicated reads is counterproductive here, since we're looking for differential expression so removing duplicated reads removes our ability to quantify this. Number of nucleotides to trim in front should be relative to the noise seen in fastQC reports. Set phred quality score minimum to Q20 and max N% to 10%. This should be sufficient with good quality reads. change output/input folders/files. Keep --failed_out for this first run, not for every pair of reads since they are pretty heavy files even if they're a few percentages of each pair. Adapter reads should be downloaded depending on the sequencing technology used. Can try using 8 threads, otherwise lower to 6 and make sure nothing else is running on computer.
Test this out on one pair before starting full run over all reads:
  fastp --verbose -i ${read1s[1]} -I ${read2s[1]} -o  /home/aurelien/data/trimmed/${read1s[1]} -O /home/aurelien/data/trimmed/${read2s[$i]} -l 25 -x -g --trim_front1 13 --trim_front2 13 --qualified_quality_phred 20 --unqualified_percent_limit 10 --thread 8 --adapter_fasta /home/aurelien/adapters/illumina_sequencing_primer_5_to_3.fa --json /home/aurelien/data/trimmed/reports/$read.fastp.json --html /home/aurelien/data/trimmed/reports/$read.fastp.html --failed_out /home/aurelien/data/trimmed/reports/$read.failed.fa --dont_eval_duplication 
Loop below iterates over every read pair. MAKE SURE READS ARE IN THE RIGHT RESPECTIVE ARRAYS AND ARRAYS ARE IN THE SAME ORDER: 
  count=${#read1s[@]}
    # make sure they're in order, then just iterate over number of pairs
    for ((i=0; i<$count; ++i)); do
    read=$(echo ${read1s[$i]}| cut -f 1-4 -d '_') 
    fastp --verbose -i ${read1s[$i]} -I ${read2s[$i]} -o  /mnt/c/Users/Aurelien/Expansion/proj28/trimmed_data/${read1s[$i]} -O /mnt/c/Users/Aurelien/Expansion/proj28/trimmed_data/${read2s[$i]} -l 25 -x -g --trim_front1 13 --trim_front2 13 --qualified_quality_phred 20 --unqualified_percent_limit 10 --thread 8 --adapter_fasta /home/aurelien/adapters/illumina_sequencing_primer_5_to_3.fa --json /mnt/c/Users/Aurelien/Expansion/proj28/trimmed_data/reports/$read.fastp.json --html /mnt/c/Users/Aurelien/Expansion/proj28/trimmed_data/reports/$read.failed.fa --dont_eval_duplication 
    done
See explanation of function and parameters below. 
    fastp --verbose -i ${read1s[$i]} -I ${read2s[$i]} \ # read inputs
    -o  /home/aurelien/data/trimmed/${read1s[$i]} -O /home/aurelien/data/trimmed/${read2s[$i]} \ # read outputs
    -l 25 -x -g --trim_front1 13 --trim_front2 13 \ # minimum length of 25, trim polyX (-x) and polyG (-g), trim 13 bps from front
    --qualified_quality_phred 20 \ # setting the phred score for filtering bases by quality to >=Q20, default is 15
    --unqualified_percent_limit 10 \ # setting percentage of bases allowed to be unqualified to 10%, default is 40    
    --thread 6 \ # worker threads, default is 3
    --adapter_fasta /home/aurelien/adapters/illumina_sequencing_primer_5_to_3.fa \ # adapter sequences
    --json /home/aurelien/data/trimmed/reports/$read.fastp.json \ # json output
    --html /home/aurelien/data/trimmed/reports/$read.fastp.html \ # html output
    --failed_out /home/aurelien/data/trimmed/reports/$read.failed.fa \ # failed sequences (under 25 after trims and quality cutting) output
    --dont_eval_duplication # Doing RNAseq, no need. Also, duplication info is available in fastqc reports + associated multiqc

Re-perform fastqc+multiqc on cleaned reads:
  fastqc *.fq.gz --memory 4096 -t 4 -o /home/aurelien/data
  multiqc ./ -o multiqc -s -v 

# Read counts through Kallisto pseudoalignment tool
Performing kallisto quant, here with 100 bootstrap samples per pair to analyse, which will allow for transcript-level abundance estimates. Quant also has option for pseudobam file if ever you want to use different downstream methods that require BAM files. Need to give gtf file to also get projected pseudoalignements to genome sorted BAM file. 
Need to know if RNAseq was done as rf-unstranded, stranded, etc. If unkown, can figure it out manually with salmon quant log results or UCSC blat (https://littlebitofdata.com/en/2017/08/strandness_in_rnaseq/)/.
Need to give kallisto index location, output diractory, and the pairs of reads. Can increase thread count (default=1) with -t
Run this once to check everything is working okay, then go with the loop:
  kallisto quant -i /home/aurelien/data/newresults/Drosophila_melanogaster.BDGP6.54.dna.transcripts.fai -t 2 -o /home/aurelien/data/newresults/kallisto /mnt/c/Users/Aurelien/Expansion/proj28/trimmed_data/PBS_IMD_6h_1_1.fq.gz /mnt/c/Users/Aurelien/Expansion/proj28/trimmed_data/PBS_IMD_6h_1_2.fq.gz
Explanation of function and parameters below.
  kallisto quant -i /home/aurelien/data/results/Drosophila_melanogaster.BDGP6.46.dna_sm.transcripts.fai # Kallisto transcriptome index file
  -t 7 # number of threads
  -b 100 # number of bootstraps
  --gtf /home/aurelien/genome/Drosophila_melanogaster.BDGP6.46.112.gtf # gtf file for pseudobam
  --pseudobam --genomebam #pseudobam creation
  -o /home/aurelien/data/results/kallisto # Output folder, where function will create a folder for each read pair
  /mnt/c/Users/Aurelien/Expansion/proj28/trimmed_data/Clean_PBS_IMD_48h_1_1.fq.gz # first file in read pair
  /mnt/c/Users/Aurelien/Expansion/proj28/trimmed_data/Clean_PBS_IMD_48h_1_2.fq.gz # second file in read pair

Run loop below: 
  for ((i=0; i<${#read1s[@]}; ++i)); do
      read=$(echo ${read1s[$i]}| cut -f 1-4 -d '_') 
      kallisto quant -i /home/aurelien/data/results_114/Drosophila_melanogaster.BDGP6.54.dna.transcripts.fai -t 7 -b 100 -o "/mnt/c/Users/Aurelien/OneDrive - Queen Mary, University of London/Documents/Experimental data analysis/RNAseq_pipeline/input/$read" /mnt/c/Users/Aurelien/Expansion/proj28/trimmed_data/${read1s[$i]} /mnt/c/Users/Aurelien/Expansion/proj28/trimmed_data/${read2s[$i]} 
  done
  
for ((i=0; i<${#read1s[@]}; ++i)); do
    read=$(echo ${read1s[$i]}| cut -f 1-4 -d '_') 
    echo $read
     done
